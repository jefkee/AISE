experiment_id,datetime,model,justification,hyperparameters,cv_accuracy,cv_precision,cv_recall,cv_f1,cv_roc_auc,data_version,accuracy,precision,recall,f1,roc_auc,tn,fp,fn,tp,interpretation,observations,next_steps
E01,2025-12-19T22:55:32,Logistic Regression (baseline),"Simple, interpretable baseline for binary classification.","{""model__C"": 3.0}",0.8127,0.5752,0.8504,0.6862,0.9086,data.csv:70acda78373d; test.csv:e10696f13c75,0.8075,0.5620,0.8393,0.6732,0.9059,9919,2516,618,3228,More false positives than false negatives; the model flags <=50K as >50K. Precision is moderate; consider feature pruning or threshold tuning.,Baseline performance established.,Improve precision with feature pruning or threshold tuning.
E02,2025-12-19T22:55:32,Random Forest (tree-based),Captures nonlinear interactions and handles mixed feature types.,"{""model__max_depth"": 16, ""model__min_samples_leaf"": 1, ""model__n_estimators"": 300}",0.8300,0.6057,0.8435,0.7050,0.9185,data.csv:70acda78373d; test.csv:e10696f13c75,0.8263,0.5927,0.8463,0.6972,0.9179,10198,2237,591,3255,More false positives than false negatives; the model flags <=50K as >50K. Precision is moderate; consider feature pruning or threshold tuning.,Model trained and evaluated on test set.,Improve precision with feature pruning or threshold tuning.
E03,2025-12-19T22:55:32,HistGradientBoosting (advanced),Boosted trees often outperform single trees and capture complex patterns.,"{""model__learning_rate"": 0.05, ""model__max_depth"": 6, ""model__max_iter"": 300}",0.8722,0.7811,0.6520,0.7107,0.9271,data.csv:70acda78373d; test.csv:e10696f13c75,0.8718,0.7759,0.6427,0.7031,0.9273,11721,714,1374,2472,More false negatives than false positives; the model misses >50K cases. Recall is moderate; consider class weighting or threshold tuning.,Recall is moderate; the model misses some >50K cases.,Tune hyperparameters and consider threshold adjustment.
